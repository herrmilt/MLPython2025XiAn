{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39347fd6",
   "metadata": {},
   "source": [
    "1. What is this code actually doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd4e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(data, K):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - K):\n",
    "        X.append(data[i:i+K])\n",
    "        y.append(data[i+K])\n",
    "\n",
    "    X = np.array(X)  # Shape: (n_samples, K)\n",
    "    y = np.array(y)  # Shape: (n_samples,)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensor = torch.from_numpy(X)\n",
    "    y_tensor = torch.from_numpy(y).unsqueeze(1)  \n",
    "\n",
    "    return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25338b",
   "metadata": {},
   "source": [
    "2. In this vanilla RNN model:\n",
    "    - What is input_size, hidden_size, and output_size\n",
    "    - What is ho, created in line 9?\n",
    "    - Which value appears in out[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f37f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla RNN Model\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        return self.fc(out[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6188fe",
   "metadata": {},
   "source": [
    "3. Explain the result shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ddb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X.shape, model(X).shape\n",
    "# Result: (torch.Size([512, 20, 1]), torch.Size([512, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33647612",
   "metadata": {},
   "source": [
    "4. What is this function actually doing?\n",
    "    - What is the torch.cat in line 12 actually doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd67d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_next_values(model, initial_seq, n_steps):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    current_seq = initial_seq.clone()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            pred = model(current_seq).item()\n",
    "            predictions.append(pred)\n",
    "            # Update sequence: remove oldest, add new prediction\n",
    "            current_seq = torch.cat([current_seq[:, 1:, :], \n",
    "                                  torch.tensor([[[pred]]]).float()], dim=1)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903606a",
   "metadata": {},
   "source": [
    "5. In this code the self.hidden is initializad in the __init__ instead of in the forward method. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 1, hidden_size = 50, out_size = 1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "    \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399b9dc",
   "metadata": {},
   "source": [
    "6. This dataloader will be using from training al LSTM neural network.\n",
    "    - Explain all the components of the X tensor, given the printed shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082326d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(X.shape)\n",
    "# printed: torch.Size([3, 7, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a7312",
   "metadata": {},
   "source": [
    "7. In the forward pass of the LSTM network, two tensors h0 and c0 are created.\n",
    "    - What are these vectors?\n",
    "    - What is the component of the resultant value of the lstm used of the linear layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    batch_size = x.shape[0]\n",
    "    h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "    c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "\n",
    "    _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "    out = self.linear(hn[0]).flatten()  \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e5006",
   "metadata": {},
   "source": [
    "8. In the example of using a RNN network for classifying digit images.\n",
    "    - Why is the input_size equal to 28\n",
    "    - What is the rationale of doing so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size=28, hidden_size=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,  # 28 pixels per row\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True  # Input shape: [batch, seq_len, input_size]\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)  # Output layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
